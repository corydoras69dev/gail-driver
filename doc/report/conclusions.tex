\chapter{Conclusions}
\label{chapter:conclusions}

As a result of this experiment, it seems that GAIL has the possibility to generate accurate imitation policy from a lot of expert data. The paper argued that GRU was superior to MLP, but the results did not show much difference.
Experiments performed with the authors' generated training data showed that the GRU produced a slightly higher generator. In the learned policies, some items had good GRU results, but the off-road rate was quite poor.


The program used "gail-driver" needed various modifications, probably due to poor maintenance. The program also had grammatical violations. Since Julia and Python sometimes overlooked grammatical violations until they were executed, there was a bug that I could not find until learning progressed, so I struggled.